import pandas as pd
import numpy as np
import json
import os
import asyncio
import aiohttp
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# 1. ì„¤ì • ë¡œë“œ
load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")

# API ì„¤ì • (REST API ì§ì ‘ í˜¸ì¶œ ë°©ì‹ì´ ë¹„ë™ê¸° ì²˜ë¦¬ì— ìœ ë¦¬í•¨)
API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={API_KEY}"

# ë™ì‹œ ì‹¤í–‰ ê°œìˆ˜ ì œí•œ ì„¤ì •
CONCURRENCY_LIMIT = 5

def convert_time_to_hours(x):
    """
    ë¬¸ìì—´ ì‹œê°„('HH:MM:SS' or 'HH:MM')ì„ ì‹¤ìˆ˜ ì‹œê°„(Hours)ìœ¼ë¡œ ë³€í™˜
    ì˜¤ë¥˜ ë°œìƒ ì‹œ NaN ë°˜í™˜
    """
    if pd.isna(x):
        return None
    
    # ì´ë¯¸ ìˆ«ìì¸ ê²½ìš° ë°”ë¡œ ë°˜í™˜
    if isinstance(x, (int, float)):
        return float(x)
        
    try:
        x = str(x).strip()
        parts = x.split(':')
        if len(parts) == 3: # HH:MM:SS
            return int(parts[0]) + int(parts[1])/60 + int(parts[2])/3600
        elif len(parts) == 2: # HH:MM
            return int(parts[0]) + int(parts[1])/60
        else:
            return float(x) # ê·¸ ì™¸ ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
    except:
        return None # ë³€í™˜ ë¶ˆê°€("11:64" ë“± ì˜ëª»ëœ í¬ë§·) -> NaN ì²˜ë¦¬


def add_full_reference_columns(df):
    """
    5ê°œ ë³€ìˆ˜ ëª¨ë‘ì— ëŒ€í•´ 'ë‚˜ë¨¸ì§€ ë³€ìˆ˜ë¡œ ê³„ì‚°í•œ ê¸°ëŒ€ê°’'ì„ ìƒì„±.
    (ë¬¸ìì—´ -> ìˆ«ì ê°•ì œ ë³€í™˜ ë° ì†Œìˆ˜ì  2ìë¦¬ ë°˜ì˜¬ë¦¼ ì ìš©)
    """
    # 0 ë‚˜ëˆ„ê¸° ë°©ì§€
    df = df.replace([np.inf, -np.inf], np.nan)

    # [í•µì‹¬ ìˆ˜ì •] ê³„ì‚°ì„ ìœ„í•´ ìˆ«ìí˜•ìœ¼ë¡œ ê°•ì œ ë³€í™˜ (ì„ì‹œ ì»¬ëŸ¼ ìƒì„±)
    # errors='coerce': ìˆ«ìë¡œ ëª» ë°”ê¾¸ëŠ” ê°’(ì˜¤íƒ€ ë“±)ì€ NaNìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ì—ëŸ¬ ë°©ì§€
    df['speed_num'] = pd.to_numeric(df['speed'], errors='coerce')
    df['fuel_num'] = pd.to_numeric(df['consumed_fuel'], errors='coerce')
    df['eff_num'] = pd.to_numeric(df['fuel_efficiency'], errors='coerce')
    df['dist_num'] = pd.to_numeric(df['distance'], errors='coerce')
    
    # ì‹œê°„ ë¬¸ìì—´ì„ ì‹¤ìˆ˜(Hour)ë¡œ ë³€í™˜
    df['time_num'] = df['time'].apply(convert_time_to_hours)

    # 1. ê±°ë¦¬ (Distance) ê²€ì¦ê°’ 2ê°œ
    # speed_numê³¼ time_numì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°í•´ì•¼ í•¨ (ì›ë˜ ì»¬ëŸ¼ X)
    df['ref_dist_phys'] = (df['speed_num'] * df['time_num']).round(2)
    df['ref_dist_fuel'] = (df['fuel_num'] * df['eff_num']).round(2)
    
    # 2. ì†Œëª¨ëŸ‰ (Fuel) ê²€ì¦ê°’
    df['ref_fuel'] = df.apply(lambda x: x['dist_num'] / x['eff_num'] if (pd.notnull(x['eff_num']) and x['eff_num'] > 0) else 0, axis=1).round(2)
    
    # 3. ì—°ë¹„ (Efficiency) ê²€ì¦ê°’
    df['ref_efficiency'] = df.apply(lambda x: x['dist_num'] / x['fuel_num'] if (pd.notnull(x['fuel_num']) and x['fuel_num'] > 0) else 0, axis=1).round(2)
    
    # 4. ì†ë„ (Speed) ê²€ì¦ê°’
    df['ref_speed'] = df.apply(lambda x: x['dist_num'] / x['time_num'] if (pd.notnull(x['time_num']) and x['time_num'] > 0) else 0, axis=1).round(2)
    
    # 5. ì‹œê°„ (Time) ê²€ì¦ê°’
    # ì‹œê°„ì€ ë‹¤ì‹œ HH:MM í˜•íƒœë¡œ ë°”ê¿€ í•„ìš” ì—†ì´, ë¹„êµë¥¼ ìœ„í•´ ì‹¤ìˆ˜(Hour) í˜•íƒœë¡œ ë‘ 
    df['ref_time'] = df.apply(lambda x: x['dist_num'] / x['speed_num'] if (pd.notnull(x['speed_num']) and x['speed_num'] > 0) else 0, axis=1).round(2)

    return df


# 2. ë¹„ë™ê¸° API í˜¸ì¶œ í•¨ìˆ˜ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
async def call_gemini_async(session, prompt, semaphore, retries=3):
    headers = {'Content-Type': 'application/json'}
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": 0.1,
            "responseMimeType": "application/json"
        }
    }
    
    async with semaphore:
        for attempt in range(retries):
            try:
                async with session.post(API_URL, headers=headers, json=data) as response:
                    if response.status == 200:
                        result = await response.json()
                        try:
                            text = result['candidates'][0]['content']['parts'][0]['text']   
                            parsed = json.loads(text)

                            if isinstance(parsed, dict):
                                return [parsed]
                            return parsed
                        except:
                            return [] # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸
                    elif response.status == 429: # Rate Limit
                        wait_time = (attempt + 1) * 5
                        print(f"â³ Rate Limit. {wait_time}ì´ˆ ëŒ€ê¸°... (ì‹œë„ {attempt+1}/{retries})")
                        await asyncio.sleep(wait_time)
                    else:
                        print(f"âš ï¸ API Error {response.status}: {await response.text()}")
                        return []
            except Exception as e:
                print(f"âš ï¸ Network Error ({attempt+1}/{retries}): {e}")
                await asyncio.sleep(3)
    
    return [] # ìµœì¢… ì‹¤íŒ¨

# 3. ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜
async def process_batch(session, month_str, stats, batch_df, semaphore):
    # ì‹¤ì œ ë°ì´í„°ì˜ JSON ë³€í™˜ (ëª¨ë¸ì— ë“¤ì–´ê°€ëŠ” ì‹¤ì œ ì…ë ¥ê°’)
    data_json = batch_df.to_json(orient='records', force_ascii=False)
    
    few_shot_examples = """
    [Case 1: Unit Error (Reurea - Force Fix)]
    - Input Context:
      - Original: {"reurea": 6}
      - References: {}
    - Reasoning: Single digit reurea (1~9) is a recording error. User input represents 'Event' not 'Volume'. Force replace with standard unit 20L. DO NOT MULTIPLY.
    - Output: [{"id": 10, "target": "reurea", "original": 6, "proposed": 20, "reference": null, "reason": "Unit error correction (Force 6 -> 20L). Standard refill volume."}]

    [Case 2: Copy-Paste Error (Variables are identical)]
    - Input Context:
      - Original: {"distance": 133.51, "consumed_fuel": 133.51, "fuel_efficiency": 2.77}
      - Stats: {"avg_dist": 450.0, "avg_fuel": 180.0}
      - References: {"ref_dist_fuel": 369.8}
    - Reasoning:
      1. Distance and Fuel are identical (133.51). Impossible physically.
      2. Fuel 133.51 is closer to avg_fuel(180) than avg_dist(450). Assume Fuel is correct.
      3. Recalculate Distance: Fuel(133.51) * Eff(2.77) = 369.8.
    - Output: [{"id": 55, "target": "distance", "original": 133.51, "proposed": 369.8, "reference": 369.8, "reason": "Copy error detected. Recalculated distance using fuel * efficiency."}]

    [Case 3: Digit Omission (Leading/Middle Digit)]
    - Input Context:
      - Original: {"distance": 36.9, "consumed_fuel": 208.01, "fuel_efficiency": 2.59}
      - References: {"ref_dist_fuel": 538.75}
    - Reasoning:
      1. Original Distance (36.9) is too small compared to Ref (538.75).
      2. Visual Check: '36.9' vs '538.75'. Missing leading digit '5' creates '536.9'.
      3. Validation: 536.9 / 208.01 = 2.58 (Matches efficiency 2.59 within tolerance).
    - Output: [{"id": 41, "target": "distance", "original": 36.9, "proposed": 536.9, "reference": 538.75, "reason": "Missing leading digit '5' detected (36.9 -> 536.9). Matches efficiency."}]

    [Case 4: Digit Omission (Fuel Example)]
    - Input Context:
      - Original: {"distance": 473.0, "consumed_fuel": 17.51, "fuel_efficiency": 2.64}
      - References: {"ref_fuel": 179.17}
    - Reasoning:
      1. Original Fuel (17.51) vs Ref (179.17).
      2. Visual Check: Missing '9' in the middle. 17.51 -> 179.51.
      3. Validation: 473.0 / 179.51 = 2.63 (Matches efficiency 2.64 within tolerance).
    - Output: [{"id": 42, "target": "consumed_fuel", "original": 17.51, "proposed": 179.51, "reference": 179.17, "reason": "Missing digit '9' detected (17.51 -> 179.51)."}]

    [Case 5: Fat Finger (Double Entry)]
    - Input Context:
      - Original: {"distance": 4718.1, "consumed_fuel": 188.51, "fuel_efficiency": 2.54}
      - References: {"ref_dist_fuel": 478.8, "ref_dist_phys": 473.1}
    - Reasoning:
      1. Original Distance (4718.1) is huge. Ref is ~478.
      2. Visual Check: '4718.1' vs '478.1'. User likely double-tapped '1' or '478' became '4718'.
      3. '478.1' is closest to Ref (478.8).
    - Output: [{"id": 22, "target": "distance", "original": 4718.1, "proposed": 478.1, "reference": 478.8, "reason": "Fat finger typo (4718.1 -> 478.1). Matches calculated distance."}]

    [Case 6: Keypad Neighbor Typo]
    - Input Context:
      - Original: {"distance": 638.1, "consumed_fuel": 184.01, "fuel_efficiency": 2.92}
      - References: {"ref_dist_fuel": 537.3}
    - Reasoning:
      1. Original (638.1) != Ref (537.3).
      2. Visual Check: '6' and '5' are neighbors on keypad. 638.1 -> 538.1.
      3. Validation: 538.1 / 184.01 = 2.92 (Exact match).
    - Output: [{"id": 35, "target": "distance", "original": 638.1, "proposed": 538.1, "reference": 537.3, "reason": "Keypad typo suspected (6->5). validated by calc."}]

    [Case 7: Ambiguous / Unsolvable (Manual Check)]
    - Input Context:
      - Original: {"time": "11:64", "distance": 500, "speed": 40}
      - References: {"ref_time_calc": "12:30"}
    - Reasoning:
      1. Time "11:64" is invalid format.
      2. Calc Time is 12:30.
      3. User might have meant 11:54 (typo) or really 12:30. Too ambiguous to auto-fix.
    - Output: [{"id": 99, "target": "manual_check", "original": "11:64", "proposed": null, "reference": null, "reason": "Invalid time format & ambiguous calculation. Requires manual review."}]
    """

    prompt = f"""
    You are a Data Cleaning Expert.
    Your goal is to detect and fix typos by comparing 'User Input' vs 'Calculated Reference'.

    [Logic: Visual Pattern Matching]
    For each row, I provide the 'Original Input' and the 'Calculated Reference' (derived from other variables).
    1. Compare the **Original** value with its corresponding **Reference** value.
    2. If they differ significantly, check if the **Reference** value looks like a corrected version of the **Original** (e.g., typo, missing digit, wrong decimal).
    3. **Priority:** Trust the value that resolves the conflict with minimum edits to the original digits.

    [Columns Provided]
    - original: distance, consumed_fuel, fuel_efficiency, speed, time
    - reference: 
    - ref_dist_phys (from Speed*Time)
    - ref_dist_fuel (from Fuel*Eff)
    - ref_fuel (from Dist/Eff)
    - ref_efficiency (from Dist/Fuel)
    - ref_speed (from Dist/Time)
    - ref_time (from Dist/Speed)

    [Few-Shot Example]
    {few_shot_examples}

    [Output Schema]
    Return a JSON list. If valid, return [].
    {{
        "id": (int),
        "target": (str),
        "original": (value),
        "proposed": (value),
        "reference": (value),
        "reason": (str)
    }}

    [Data to Analyze]
    {data_json}
    """

    return await call_gemini_async(session, prompt, semaphore)


# 4. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
async def main_async():
    current_dir = Path(__file__).resolve().parent
    project_root = current_dir.parent

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    input_path = project_root / 'data' / 'processed' / 'driving_log_2016_2020_cleaned.csv'

    output_filename = f'cleaning_proposal_ai_{timestamp}.csv'
    output_path = project_root / 'data' / output_filename

    print("ğŸš€ ì´ˆê³ ì† AI ë°ì´í„° í´ë¦¬ë‹ ì‹œì‘ (Async Batch Processing)...")
    print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼ëª…: {output_filename}")

    # ê²°ê³¼ íŒŒì¼ ì´ˆê¸°í™”
    header_df = pd.DataFrame(columns=['id', 'target', 'original', 'proposed', 'reference', 'reason'])
    header_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    

    # 1. ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(input_path)

    print("âš¡ ëª¨ë“  ë°ì´í„°ì— ëŒ€í•œ ì°¸ì¡°ê°’(Reference) ê³„ì‚° ì¤‘...")
    df = add_full_reference_columns(df)

    # 2. ë‚ ì§œ ë° ê¸°íƒ€ ì„¤ì •
    df['id'] = df.index
    df['date_dt'] = pd.to_datetime(df['date'])
    df['month'] = df['date_dt'].dt.to_period('M')

    # ì„¸ë§ˆí¬ì–´ ìƒì„± (ë™ì‹œ ì‹¤í–‰ ê°œìˆ˜ 5ê°œë¡œ ì œí•œ)
    semaphore = asyncio.Semaphore(CONCURRENCY_LIMIT)
    
    # TCPConnector ì„¤ì • (ì—°ê²° ëŠê¹€ ë°©ì§€, ê°•ì œ ì¢…ë£Œ í—ˆìš©)
    connector = aiohttp.TCPConnector(limit=10, force_close=True)

    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = []
        
        # ì›”ë³„ ë£¨í”„ -> Task ìƒì„±
        for month, group in df.groupby('month'):
            # 1. í•´ë‹¹ ì›”ì˜ í†µê³„ ì •ë³´ ì¶”ì¶œ (í”„ë¡¬í”„íŠ¸ ì»¨í…ìŠ¤íŠ¸ìš©)
            stats = {
                'fuel_efficiency': group['fuel_efficiency'].mean(),
                'distance': group['distance'].mean()
            }
            
            # --- [í•„í„°ë§ ë¡œì§ ìµœì í™”: ë²¡í„°í™” ì—°ì‚° ì‚¬ìš©] ---
            
            # ì¡°ê±´ 1: ì—°ë¹„ ì‹œìŠ¤í…œ ê²€ì¦ (ì—„ê²©í•œ ê¸°ì¤€: 1% ì˜¤ì°¨)
            # (ê±°ë¦¬/ì†Œëª¨ëŸ‰)ê³¼ (ê¸°ë¡ëœ ì—°ë¹„)ê°€ 1% ì´ìƒ ì°¨ì´ë‚˜ë©´ ì˜ì‹¬
            # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€ë¥¼ ìœ„í•´ ë¶„ëª¨ê°€ 0ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ê³„ì‚°
            mask_fuel = (
                (group['consumed_fuel'] > 0) & 
                (group['fuel_efficiency'] > 0) &
                (abs((group['distance'] / group['consumed_fuel'] - group['fuel_efficiency']) / group['fuel_efficiency']) > 0.01)
            )

            # ì¡°ê±´ 2: ë¬¼ë¦¬ ì‹œìŠ¤í…œ ê²€ì¦ (ê´€ëŒ€í•œ ê¸°ì¤€: 5% ì˜¤ì°¨)
            # (ê±°ë¦¬)ì™€ (ì°¸ì¡°ê±°ë¦¬: ì†ë„*ì‹œê°„)ê°€ 5% ì´ìƒ ì°¨ì´ë‚˜ë©´ ì˜ì‹¬
            # ref_dist_physê°€ ì¡´ì¬í•˜ê³ (NaNì´ ì•„ë‹ˆê³ ), ê±°ë¦¬ê°€ 0ë³´ë‹¤ í´ ë•Œë§Œ ê³„ì‚°
            mask_phys = (
                (group['ref_dist_phys'].notna()) & 
                (group['distance'] > 0) &
                (abs(group['distance'] - group['ref_dist_phys']) / group['distance'] > 0.05)
            )

            # ì¡°ê±´ 3: ì‹œê°„ í¬ë§· ì˜¤ë¥˜ ê²€ì¦
            # "25:00", "12:70" ê°™ì€ ë¹„ì •ìƒì ì¸ ì‹œê°„ í˜•ì‹ ì°¾ê¸°
            def is_invalid_time(t):
                if pd.isna(t) or ':' not in str(t): return False
                try:
                    h, m, s = map(int, str(t).split(':'))
                    return h >= 24 or m >= 60 # 24ì‹œ ì´ìƒì´ê±°ë‚˜ 60ë¶„ ì´ìƒì´ë©´ ì˜¤ë¥˜
                except:
                    return True # íŒŒì‹± ì—ëŸ¬ë‚˜ë©´ ì˜¤ë¥˜ë¡œ ê°„ì£¼

            mask_time = group['time'].apply(is_invalid_time)

            # ì¡°ê±´ 4: ìš”ì†Œìˆ˜ ë‹¨ìœ„ ì˜¤ë¥˜ ê²€ì¦
            # 1, 2, 6 ë“± í•œ ìë¦¬ ìˆ˜ëŠ” ë‹¨ìœ„ ì˜¤ë¥˜(í†µ ë‹¨ìœ„)ì¼ í™•ë¥  ë†’ìŒ
            mask_reurea = (
                (group['reurea'].notna()) & 
                (group['reurea'].isin([1, 2, 6]))
            )

            # --- [ìµœì¢… í•„í„°ë§ ë° ë°°ì¹˜ ì²˜ë¦¬] ---
            
            # ìœ„ 4ê°€ì§€ ì¡°ê±´ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹ë˜ë©´(OR ì—°ì‚° |) ì˜ì‹¬ ë°ì´í„°ë¡œ ê°„ì£¼
            suspect_df = group[mask_fuel | mask_phys | mask_time | mask_reurea].copy()
            
            # ì˜ì‹¬ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ë°°ì¹˜ ì‘ì—… ìƒì„±
            if not suspect_df.empty:
                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ì—¬ Dict ë³€í™˜ (ë©”ëª¨ë¦¬ ì ˆì•½)
                target_cols = ['id', 'date', 'vehicle_id', 'distance', 'consumed_fuel', 
                            'fuel_efficiency', 'time', 'speed', 'reurea']
                
                # 15ê°œì”© ì˜ë¼ì„œ ì²˜ë¦¬ (Batch Processing)
                batch_size = 15
                for i in range(0, len(suspect_df), batch_size):
                    batch_slice = suspect_df.iloc[i:i+batch_size][target_cols]
                    
                    # Task ì˜ˆì•½ (API í˜¸ì¶œ í•¨ìˆ˜ì— ì „ë‹¬)
                    tasks.append(process_batch(session, str(month), stats, batch_slice, semaphore))

        print(f"ğŸ“¦ ì´ {len(tasks)}ê°œì˜ ë°°ì¹˜ ì‘ì—…ì´ ì˜ˆì•½ë˜ì—ˆìŠµë‹ˆë‹¤. ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ë³‘ë ¬ ì‹¤í–‰ ë° ì‹¤ì‹œê°„ ì €ì¥ (Streaming Save)
        total_corrections = 0
        
        # as_completed: ë¨¼ì € ëë‚˜ëŠ” ì‘ì—…ë¶€í„° ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
        for future in asyncio.as_completed(tasks):
            proposals = await future
            if proposals:
                res_df = pd.DataFrame(proposals)
                
                # [ì¤‘ìš”] ìˆ˜ì • ì œì•ˆì´ ì—†ëŠ” ë°ì´í„°(ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë“±)ë‚˜ ì˜ëª»ëœ í‚¤ê°€ ìˆëŠ” í–‰ í•„í„°ë§
                if res_df.empty or 'target' not in res_df.columns:
                    continue
                
                # is_error í‚¤ê°€ í˜¹ì‹œ ë‚¨ì•„ìˆë‹¤ë©´ ì œê±° (í”„ë¡¬í”„íŠ¸ì—ì„œ ì œì™¸í–ˆì§€ë§Œ ì•ˆì „ì¥ì¹˜)
                if 'is_error' in res_df.columns:
                    res_df = res_df[res_df['is_error'] != False]

                # ì €ì¥í•  ì»¬ëŸ¼ë§Œ ì„ íƒ (original ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ NaN ì²˜ë¦¬ë¨)
                cols_to_save = ['id', 'target', 'original', 'proposed', 'reference', 'reason']
                for col in cols_to_save:
                    if col not in res_df.columns:
                        res_df[col] = None 
                
                res_df = res_df[cols_to_save]
                
                # idê°€ ì—†ëŠ” í–‰(ì“°ë ˆê¸° ë°ì´í„°) ì œê±°
                res_df = res_df.dropna(subset=['id'])

                res_df.to_csv(output_path, mode='a', header=False, index=False, encoding='utf-8-sig', lineterminator='\n')
            
            count = len(res_df)
            total_corrections += count
            print(f"âœ… ë°°ì¹˜ ì™„ë£Œ: {count}ê±´ ì €ì¥ë¨ (ëˆ„ì  {total_corrections}ê±´)")
        else:
            print(".", end="", flush=True)
    print("ğŸ§¹ ìµœì¢… ê²°ê³¼ ì •ë ¬ ì¤‘...")
    try:
        final_df = pd.read_csv(output_path)
        if not final_df.empty:
            final_df = final_df.sort_values(by='id') # id ê¸°ì¤€ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
            final_df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print("âœ¨ ì •ë ¬ ì™„ë£Œ.")
    except Exception as e:
        print(f"âš ï¸ ì •ë ¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë°ì´í„°ëŠ” ë³´ì¡´ë¨): {e}")

    print(f"\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ! ì´ {total_corrections}ê±´ì˜ ë°ì´í„°ê°€ ìˆ˜ì • ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“‚ ê²°ê³¼ íŒŒì¼: {output_path}")

if __name__ == "__main__":
    # ìœˆë„ìš° í™˜ê²½ì—ì„œ asyncio ì—ëŸ¬ ë°©ì§€
    if os.name == 'nt':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main_async())